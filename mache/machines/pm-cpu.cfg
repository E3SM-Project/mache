# Options related to deploying an e3sm-unified conda environment on supported
# machines
[e3sm_unified]

# the unix group for permissions for the e3sm-unified conda environment
group = e3sm

# the compiler set to use for system libraries and MPAS builds
compiler = gnu

# the system MPI library to use for intel18 compiler
mpi = mpich

# the path to the directory where activation scripts, the base environment, and
# system libraries will be deployed
base_path = /global/common/software/e3sm/anaconda_envs

# whether to use E3SM modules for hdf5, netcdf-c, netcdf-fortran and pnetcdf
# (spack modules are used otherwise)
use_e3sm_hdf5_netcdf = True


# config options related to data needed by diagnostics software such as
# e3sm_diags and MPAS-Analysis
[diagnostics]

# The base path to the diagnostics directory
base_path = /global/cfs/cdirs/e3sm/diagnostics

# the unix group for permissions for diagnostics
group = e3sm


# config options associated with web portals
[web_portal]

# The path to the base of the web portals
base_path = /global/cfs/cdirs/e3sm/www

# The base URL that corresponds to the base path
base_url = https://portal.nersc.gov/cfs/e3sm


# The parallel section describes options related to running jobs in parallel
[parallel]

# parallel system of execution: slurm, cobalt or single_node
system = slurm

# whether to use mpirun or srun to run a task
parallel_executable = srun

# cores per node on the machine
cores_per_node = 256

# account for running diagnostics jobs
account = e3sm

# available constraint(s) (default is the first)
constraints = cpu

# quality of service (default is the first)
qos = regular, debug, premium

# Config options related to spack environments
[spack]

# whether to load modules from the spack yaml file before loading the spack
# environment
modules_before = False

# whether to load modules from the spack yaml file after loading the spack
# environment
modules_after = False

# whether the machine uses cray compilers
cray_compilers = True


# config options related to synchronizing files
[sync]

# the full hostname of the machine
hostname = perlmutter-p1.nersc.gov
